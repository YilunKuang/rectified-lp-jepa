defaults:
  - _self_
  - augmentations: symmetric.yaml
  - wandb: private.yaml
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

# disable hydra outputs
hydra:
  output_subdir: null
  run:
    dir: .

name: "simclr-vit-imagenet100"
method: "simclr"
backbone:
  name: "vit_small"

method_kwargs:
  proj_hidden_dim: 4096
  proj_output_dim: 512
  temperature: 0.2
  projector_type: "standard"
  add_projector_classifier: true # add this everywehere we want to log projector metrics as a method kwarg

mlp_probe:
  enabled: False
  num_layers: 3


data:
  dataset: imagenet100
  train_path: "/imagenet100_real/train" # yash change temprorary to see if this works
  val_path: "/imagenet100_real/val" # absolute path into squashfs overlay
  # train_path: "./datasets/imagenet100/train"
  # val_path: "./datasets/imagenet100/val"
  preload: True  # This enables the in-memory cache
  format: "image_folder"
  num_workers: 4

augmentations:
  - rrc:
      enabled: True
      crop_min_scale: 0.2
      crop_max_scale: 1.0
    color_jitter:
      enabled: True
      brightness: 0.4
      contrast: 0.4
      saturation: 0.2
      hue: 0.1
      prob: 0.8
    grayscale:
      enabled: True
      prob: 0.2
    gaussian_blur:
      enabled: True
      prob: 0.5
    solarization:
      enabled: True
      prob: 0.1
    equalization:
      enabled: False
      prob: 0.0
    horizontal_flip:
      enabled: True
      prob: 0.5
    crop_size: 224
    num_crops: 2



optimizer:
  name: "adamw" # VIT
  batch_size: 128 # changed from 256 to 128 for imagenet100
  lr: 5e-4 # VIT
  classifier_lr: 5e-3
  weight_decay: 1e-4
  # kwargs:
  #   clip_lr: True
  #   eta: 0.02
  #   exclude_bias_n_norm: True
scheduler:
  name: "warmup_cosine"
checkpoint:
  enabled: True
  dir: "trained_models"
  frequency: 1
auto_resume:
  enabled: False

# overwrite PL stuff
max_epochs: 1000
devices: [0]
sync_batchnorm: True
accelerator: "gpu"
strategy: "ddp"
precision: 16-mixed